{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba3da736-f749-4e41-930d-4c2b75fd1d89",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "%pip install semantic-link==0.11.1 semantic-link-labs==0.11.2  > /dev/null 2>&1\n",
    "import pandas as pd\n",
    "import requests \n",
    "import json\n",
    "import base64\n",
    "import sempy_labs as labs\n",
    "from sempy_labs import migration, directlake\n",
    "import sempy_labs.report as rep \n",
    "import sempy.fabric as semfabric\n",
    "from urllib.parse import urlparse, unquote\n",
    "from typing import Union, Optional\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "619cd71a-8957-4d5a-b80a-71dda04de081",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-01T20:34:53.2783087Z",
       "execution_start_time": "2025-11-01T20:34:52.8915911Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "9a988850-c3c8-41a8-a8e3-8e0e681771df",
       "queued_time": "2025-11-01T20:33:38.6070967Z",
       "session_id": "07d80e2d-a99f-4210-9687-6821d94cc581",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 10,
       "statement_ids": [
        10
       ]
      },
      "text/plain": [
       "StatementMeta(, 07d80e2d-a99f-4210-9687-6821d94cc581, 10, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "## You can change these as you like\n",
    "lakehouse_name = 'Baraa_LH'\n",
    "warehouse_name = 'Baraa_WH'\n",
    "semantic_model_name = 'Baraa_SMM'\n",
    "report_name = 'Baraa_Report'\n",
    "gold_notebook_name = 'gold_layer_processing_notebook'\n",
    "silver_notebook_name = 'silver_layer_processing_notebook'\n",
    "timezone = \"Africa/Lagos\"\n",
    "\n",
    "## Don't Change these ⚠️⚠️⚠️⚠️⚠️⚠️⚠️\n",
    "crm_data_relative_path = \"datasets/source_crm\"\n",
    "erp_data_relative_path = \"datasets/source_erp\"\n",
    "\n",
    "workspace_name=notebookutils.runtime.context['currentWorkspaceName']\n",
    "workspace_id = notebookutils.runtime.context['currentWorkspaceId']\n",
    "\n",
    "create_semantic_model_uri = f\"v1/workspaces/{workspace_id}/semanticModels\"\n",
    "semantic_model_github_url = \"https://github.com/maleek004/baraaE2E/tree/main/FakemazonSMM.SemanticModel\"\n",
    "semantic_model_parts = ''\n",
    "semantic_model_request_body= ''\n",
    "semantic_model_id = ''\n",
    "\n",
    "create_report_uri = f\"v1/workspaces/{workspace_id}/reports\"\n",
    "report_github_folder = 'https://github.com/maleek004/baraaE2E/tree/main/auto%20generated%20report.Report'\n",
    "report_parts = ''\n",
    "create_report_request_body = ''\n",
    "report_id =''\n",
    "\n",
    "silver_notebook_url = 'https://raw.githubusercontent.com/maleek004/auto-fabric-setup-baraa/refs/heads/main/Create_silver_layer_Notebook.ipynb'\n",
    "gold_notebook_url= 'https://raw.githubusercontent.com/maleek004/auto-fabric-setup-baraa/refs/heads/main/Load_gold_layer.ipynb'\n",
    "\n",
    "crm_dataset_urls = {\"cust_info.csv\":\"https://raw.githubusercontent.com/DataWithBaraa/sql-data-warehouse-project/refs/heads/main/datasets/source_crm/cust_info.csv\"\n",
    "                    ,\"prd_info.csv\":\"https://raw.githubusercontent.com/DataWithBaraa/sql-data-warehouse-project/refs/heads/main/datasets/source_crm/prd_info.csv\"\n",
    "                    ,\"sales_details.csv\":\"https://raw.githubusercontent.com/DataWithBaraa/sql-data-warehouse-project/refs/heads/main/datasets/source_crm/sales_details.csv\"}\n",
    "\n",
    "erp_dataset_urls = {\"CUST_AZ12.csv\":\"https://raw.githubusercontent.com/DataWithBaraa/sql-data-warehouse-project/refs/heads/main/datasets/source_erp/CUST_AZ12.csv\"\n",
    "                    ,\"LOC_A101.csv\":\"https://raw.githubusercontent.com/DataWithBaraa/sql-data-warehouse-project/refs/heads/main/datasets/source_erp/LOC_A101.csv\"\n",
    "                    ,\"PX_CAT_G1V2.csv\":\"https://raw.githubusercontent.com/DataWithBaraa/sql-data-warehouse-project/refs/heads/main/datasets/source_erp/PX_CAT_G1V2.csv\"}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0a642325",
   "metadata": {},
   "source": [
    "## Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "466e4d05-4b51-4825-8249-b42758586f1d",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-01T20:34:53.9274919Z",
       "execution_start_time": "2025-11-01T20:34:53.6145092Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "54eb45d2-fa94-46b4-a55b-27d191fb8735",
       "queued_time": "2025-11-01T20:33:38.6120037Z",
       "session_id": "07d80e2d-a99f-4210-9687-6821d94cc581",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 12,
       "statement_ids": [
        12
       ]
      },
      "text/plain": [
       "StatementMeta(, 07d80e2d-a99f-4210-9687-6821d94cc581, 12, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "####################### FOR SENDING POST REQUESTS TO FABRIC REST API (WITHOUT BEARER TOKEN)\n",
    "def fabriclient_post(url, request_body):\n",
    "\n",
    "    client = semfabric.FabricRestClient()\n",
    "    \n",
    "    response = client.request(method = \"POST\", path_or_url=url, lro_wait=True, json = request_body)\n",
    "    print(response.status_code)\n",
    "    print(response.text)\n",
    "    response.raise_for_status()\n",
    "    \n",
    "    response_json = response.json()\n",
    "    return response_json.get('id')\n",
    "\n",
    "####################### THIS FUNCTION EXTRACTS THE DEFINITION PART OF AN ITEM SYNCED TO GITHUB AND RETURNS THE FULL LIST WITH BASE64 PAYLOAD\n",
    "\n",
    "def get_definition_parts_from_github(github_folder_url, isReport=False, report_pbir_definition: Optional[Union[dict, str, bytes]] = None):\n",
    "    \"\"\"\n",
    "    Given a GitHub folder URL, recursively retrieves all files under it\n",
    "    and returns a 'parts' list formatted like:\n",
    "    [\n",
    "        {\n",
    "            \"path\": \"definition.pbism\",\n",
    "            \"payload\": \"<base64 string>\",\n",
    "            \"payloadType\": \"InlineBase64\"\n",
    "        },\n",
    "        ...\n",
    "    ]\n",
    "\n",
    "    Parameters:\n",
    "    ----------\n",
    "    github_folder_url : str\n",
    "        The GitHub folder URL to process.\n",
    "    isReport : bool, optional\n",
    "        Set to True if the folder represents a Power BI report.\n",
    "        If True, `report_pbir_definition` must be provided.\n",
    "    report_pbir_definition : bytes, optional\n",
    "        The customized definition.pbir file to use (required if isReport=True).\n",
    "\n",
    "    Raises:\n",
    "    -------\n",
    "    ValueError\n",
    "        If isReport=True but report_pbir_definition is not provided.\n",
    "    \"\"\"\n",
    "\n",
    "    # ---  Validate parameters ---\n",
    "    if isReport and report_pbir_definition is None:\n",
    "        raise ValueError(\n",
    "            \"Since you are trying to build a report, you must provide a custom 'definition.pbir' \"\n",
    "            \"file that includes a 'byConnection' dataReference and the target 'semanticmodelid'.\\n\"\n",
    "            \"For more information, visit: \"\n",
    "            \"https://learn.microsoft.com/en-us/power-bi/developer/projects/projects-report\"\n",
    "            \"?tabs=v2%2Cdesktop#definitionpbir\"\n",
    "        )\n",
    "    # --- Helper: Parse the folder URL ---\n",
    "    def parse_github_folder_url(url: str):\n",
    "        parsed = urlparse(url)\n",
    "        path_parts = parsed.path.strip(\"/\").split(\"/\")\n",
    "\n",
    "        if len(path_parts) < 2:\n",
    "            raise ValueError(\"Invalid GitHub URL format.\")\n",
    "\n",
    "        owner = path_parts[0]\n",
    "        repo = path_parts[1]\n",
    "\n",
    "        # Handle 'tree/main/...'\n",
    "        if len(path_parts) > 3 and path_parts[2] in (\"tree\", \"blob\"):\n",
    "            subpath = \"/\".join(path_parts[4:])\n",
    "        else:\n",
    "            subpath = \"/\".join(path_parts[2:])\n",
    "\n",
    "        return owner, repo, unquote(subpath)\n",
    "\n",
    "    # --- Helper: Recursively fetch all files and relative paths ---\n",
    "    def get_all_files_with_relative_paths(owner: str, repo: str, base_path: str, current_path: str = None):\n",
    "        if current_path is None:\n",
    "            current_path = base_path\n",
    "\n",
    "        api_url = f\"https://api.github.com/repos/{owner}/{repo}/contents/{current_path}\"\n",
    "        response = requests.get(api_url)\n",
    "        response.raise_for_status()\n",
    "        items = response.json()\n",
    "\n",
    "        files = []\n",
    "        for item in items:\n",
    "            if item[\"type\"] == \"file\":\n",
    "                relative_path = item[\"path\"].replace(base_path + \"/\", \"\")\n",
    "                files.append({\n",
    "                    \"raw_url\": item[\"download_url\"],\n",
    "                    \"relative_path\": relative_path\n",
    "                })\n",
    "            elif item[\"type\"] == \"dir\":\n",
    "                files.extend(get_all_files_with_relative_paths(owner, repo, base_path, item[\"path\"]))\n",
    "        return files\n",
    "\n",
    "    # --- Helper: Download and encode file content to Base64 ---\n",
    "    def download_and_encode_base64(url: str) -> str:\n",
    "        response = requests.get(url)\n",
    "        response.raise_for_status()\n",
    "        file_content = response.content  # .content was the safest option\n",
    "        return base64.b64encode(file_content).decode(\"utf-8\")\n",
    "\n",
    "    # --- Main flow ---\n",
    "    owner, repo, subpath = parse_github_folder_url(github_folder_url)\n",
    "    files = get_all_files_with_relative_paths(owner, repo, subpath)\n",
    "\n",
    "    parts = []\n",
    "    for file in files:\n",
    "        if isReport and file['relative_path'] == 'definition.pbir':\n",
    "            # Safely handle dicts, strings, or bytes\n",
    "            if isinstance(report_pbir_definition, dict):\n",
    "                report_pbir_definition_bytes = json.dumps(report_pbir_definition, indent=2).encode(\"utf-8\")\n",
    "            elif isinstance(report_pbir_definition, str):\n",
    "                report_pbir_definition_bytes = report_pbir_definition.encode(\"utf-8\")\n",
    "            else:\n",
    "                report_pbir_definition_bytes = report_pbir_definition  # assume bytes\n",
    "            encoded = base64.b64encode(report_pbir_definition).decode(\"utf-8\")\n",
    "        else:\n",
    "            encoded = download_and_encode_base64(file[\"raw_url\"])\n",
    "        parts.append({\n",
    "            \"path\": file[\"relative_path\"],\n",
    "            \"payload\": encoded,\n",
    "            \"payloadType\": \"InlineBase64\"\n",
    "        })\n",
    "\n",
    "    print(f\"✅ Retrieved {len(parts)} files from {repo}/{subpath}\")\n",
    "    return parts\n",
    "\n",
    "##################### THIS FUNCTION DOWNLOADS DATASET TO LAKEHOUSE\n",
    "def download_datasets(dataset_urls, save_dir=\".\"):\n",
    "    for filename, url in dataset_urls.items():\n",
    "        print(f\"Downloading {filename}...\")\n",
    "        try:\n",
    "            response = requests.get(url, timeout=15)\n",
    "            response.raise_for_status()  # Raise exception for HTTP errors\n",
    "            with open(f\"{save_dir}/{filename}\", \"wb\") as f:\n",
    "                f.write(response.content)\n",
    "            print(f\"✅ {filename} downloaded successfully.\")\n",
    "        except requests.exceptions.RequestException as e:\n",
    "            print(f\"❌ Failed to download {filename}: {e}\")\n",
    "\n",
    "################ download notebook from github and optionally attach it to a lakehouse\n",
    "def import_notebook(notebook_import_name, githuburl, update_lakehouse=False , workspace_id=None, lakehouse_name=None ) -> str:\n",
    "    # import notebook and return notebook_id\n",
    "    result = labs.import_notebook_from_web( notebook_name=notebook_import_name, url=githuburl)\n",
    "        \n",
    "    # update the default lakehouse (only if allowed)\n",
    "    if update_lakehouse:\n",
    "        if not workspace_id or not lakehouse_name:\n",
    "            raise ValueError(\"workspace_id and lakehouse_name must be provided when update_lakehouse=True\")\n",
    "        notebookutils.notebook.updateDefinition(\n",
    "            name=notebook_import_name, \n",
    "            workspaceId=workspace_id, \n",
    "            defaultLakehouse=lakehouse_name, \n",
    "            defaultLakehouseWorkspace=workspace_id\n",
    "        )\n",
    "    \n",
    "    # Return notebook id\n",
    "    notebook_id = semfabric.resolve_item_id(item_name=notebook_import_name, type=\"Notebook\")\n",
    "\n",
    "    print(f\"notebookname: {notebook_import_name}, notebook_id: {notebook_id}\")\n",
    "\n",
    "    return notebook_id\n",
    "\n",
    "##########\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c6bd3e7e",
   "metadata": {},
   "source": [
    "## Create Lakehouse\n",
    "#### Created directories in the lakehouse\n",
    "#### Mounted the file directory of the lakehouse so that we can write files to it directly\n",
    "#### Downloaded files from Github into folders in the Lakehouse  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8315a6f1-5ec3-4b16-b42c-f92aef527f4a",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [
    {
     "data": {
      "application/vnd.livy.statement-meta+json": {
       "execution_finish_time": "2025-11-01T20:35:00.0850339Z",
       "execution_start_time": "2025-11-01T20:34:53.9294862Z",
       "livy_statement_state": "available",
       "normalized_state": "finished",
       "parent_msg_id": "dd73ee8c-7ee2-4d5b-90fd-af8007c0ab52",
       "queued_time": "2025-11-01T20:33:38.6144689Z",
       "session_id": "07d80e2d-a99f-4210-9687-6821d94cc581",
       "session_start_time": null,
       "spark_pool": null,
       "state": "finished",
       "statement_id": 13,
       "statement_ids": [
        13
       ]
      },
      "text/plain": [
       "StatementMeta(, 07d80e2d-a99f-4210-9687-6821d94cc581, 13, Finished, Available, Finished)"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/plain": [
       "'abfss://63bd4ac8-18b7-4ec1-8ee9-681feee6113e@onelake.dfs.fabric.microsoft.com/84285eaa-9ab8-4dc9-8ecc-005a40bcda83'"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# creating a new lakehouse where our data will be downladed will be downloaded into and will alsoe be used as the siver layer\n",
    "\n",
    "lakehouse = notebookutils.lakehouse.create(lakehouse_name)    \n",
    "lakehouse_id = lakehouse['id']\n",
    "abfs_path = lakehouse.get('properties',{}).get('abfsPath')\n",
    "abfs_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "efcc6050-3a41-4329-8027-ba6989602d00",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# creating directories in our destination lakehouse (that this notebook is not attached to, hence the use of abfs_path) \n",
    "notebookutils.fs.mkdirs(f'{abfs_path}/Files/{crm_data_relative_path}')\n",
    "notebookutils.fs.mkdirs(f'{abfs_path}/Files/{erp_data_relative_path}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "238ae84f-8b8a-43b7-be4d-dd141a02e892",
   "metadata": {
    "collapsed": false,
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "##  mount the Files section of the new lakehouse \n",
    "files_directory = abfs_path + '/Files'\n",
    "mount_point = \"/mnt/lakehouse/\" + lakehouse_name + \"/Files\"\n",
    "notebookutils.fs.mount(files_directory, mount_point)\n",
    "base_dir_local_path = notebookutils.fs.getMountPath(mount_point)\n",
    "base_dir_local_path"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5b1f973e-863e-42f8-9371-2d4d5d984723",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "crm_data_full_local_path = f'{base_dir_local_path}/{crm_data_relative_path}'\n",
    "erp_data_full_local_path = f'{base_dir_local_path}/{erp_data_relative_path}'\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "67f123d5-21a4-4878-b620-1befdd110cd0",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "# Download datasets to the lakehouse\n",
    "download_datasets(crm_dataset_urls, crm_data_full_local_path)\n",
    "download_datasets(erp_dataset_urls, erp_data_full_local_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4c1e08f1",
   "metadata": {},
   "source": [
    "## Create Warehouse"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2fa6faaa-a2e6-40e1-b27e-f93aea297e2b",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#Creating a warehouse where our gold layer views and tables will be stored\n",
    "url = f\"https://api.fabric.microsoft.com/v1/workspaces/{workspace_id}/warehouses\"\n",
    "request_body = {\"displayName\": warehouse_name}\n",
    "\n",
    "warehouse_id = fabriclient_post(url,request_body)\n",
    "warehouse_id"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "09921039",
   "metadata": {},
   "source": [
    "## Download and run transformation notebooks "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d60a7944-288c-4041-bae3-6b669e2caf42",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "#import notebooks and get Notebook Ids for the 2 notebooks to be used in subsequent steps\n",
    "silver_layer_notebook_id = import_notebook(notebook_import_name=silver_notebook_name, githuburl=silver_notebook_url, update_lakehouse=True, workspace_id=workspace_id, lakehouse_name = lakehouse_name)\n",
    "gold_layer_notebook_id = import_notebook(gold_notebook_name,gold_notebook_url)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af5bdb50-cbd0-4ddb-aa96-fcbfa85eae50",
   "metadata": {
    "microsoft": {
     "language": "python",
     "language_group": "jupyter_python"
    }
   },
   "outputs": [],
   "source": [
    "DAG = {\n",
    "    \"activities\": [\n",
    "        {\n",
    "            \"name\": silver_notebook_name, \n",
    "            \"path\": silver_notebook_name, \n",
    "            \"timeoutPerCellInSeconds\": 90,\n",
    "            \"args\": {\"useRootDefaultLakehouse\": True, \"abfs_path\":abfs_path, \"workspaceId\": workspace_id , \"lakehouseId\": lakehouse_id , \"timezone\" : timezone}\n",
    "        },\n",
    "        {\n",
    "            \"name\": gold_notebook_name,\n",
    "            \"path\": gold_notebook_name,\n",
    "            \"timeoutPerCellInSeconds\": 90,\n",
    "            \"args\":{\"lakehouse_name\": lakehouse_name , \"warehouse_name\":warehouse_name},\n",
    "            \"retry\": 2, ### because it takes a while for the SQL endpoint of the lakehouse to refresh, and we will be depending on it so the first try might fail...\n",
    "            \"retryIntervalInSeconds\": 20,\n",
    "            \"dependencies\": [silver_notebook_name]\n",
    "        }\n",
    "    ],\n",
    "    \"timeoutInSeconds\": 480, # max 4 mins for the entire pipeline\n",
    "}\n",
    "\n",
    "notebookutils.notebook.runMultiple(DAG, {\"displayDAGViaGraphviz\":True})"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d6e9f94f",
   "metadata": {},
   "source": [
    "### Create semantic model from Fabric REST API and attach it to warehouse\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b8657002",
   "metadata": {},
   "outputs": [],
   "source": [
    "semantic_model_parts = get_definition_parts_from_github(semantic_model_github_url)\n",
    "semantic_model_request_body= {\n",
    "                                \"displayName\": semantic_model_name,\n",
    "                                \"description\": \"semantic model for E2E demo\",\n",
    "                                \"definition\":{\n",
    "                                        \"parts\": semantic_model_parts\n",
    "                                } \n",
    "                            }\n",
    "\n",
    "semantic_model_id = fabriclient_post(create_semantic_model_uri, semantic_model_request_body)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0ebdd469",
   "metadata": {},
   "outputs": [],
   "source": [
    "labs.directlake.update_direct_lake_model_connection(dataset = semantic_model_name,source= warehouse_name, source_type=\"Warehouse\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "831bba6e",
   "metadata": {},
   "source": [
    "## Create report "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2bf110a0",
   "metadata": {},
   "outputs": [],
   "source": [
    "custom_pbir = {\n",
    "    \"$schema\": \"https://developer.microsoft.com/json-schemas/fabric/item/report/definitionProperties/2.0.0/schema.json\",\n",
    "    \"version\": \"4.0\",\n",
    "    \"datasetReference\": {\n",
    "        \"byConnection\": {\n",
    "            \"connectionString\": f\"semanticmodelid={semantic_model_id}\"\n",
    "        }\n",
    "    }\n",
    "}\n",
    "\n",
    "report_parts = get_definition_parts_from_github(report_github_folder, isReport=True , report_pbir_definition=custom_pbir)\n",
    "create_report_request_body = {\n",
    "        \"displayName\": report_name,\n",
    "        \"description\": \"report created using Fabric REST API\",\n",
    "        \"definition\" : {\n",
    "            \"parts\": report_parts\n",
    "            }\n",
    "        }\n",
    "report_id = fabriclient_post(create_report_uri, create_report_request_body)"
   ]
  }
 ],
 "metadata": {
  "dependencies": {},
  "kernel_info": {
   "jupyter_kernel_name": "python3.11",
   "name": "jupyter"
  },
  "kernelspec": {
   "display_name": "Jupyter",
   "name": "jupyter"
  },
  "language_info": {
   "name": "python"
  },
  "microsoft": {
   "language": "python",
   "language_group": "jupyter_python",
   "ms_spell_check": {
    "ms_spell_check_language": "en"
   }
  },
  "nteract": {
   "version": "nteract-front-end@1.0.0"
  },
  "spark_compute": {
   "compute_id": "/trident/default",
   "session_options": {
    "conf": {
     "spark.synapse.nbs.session.timeout": "1200000"
    }
   }
  },
  "synapse_widget": {
   "state": {
    "006515ce-611b-4817-be7e-51ab166a7e97": {
     "persist_state": {
      "view": {
       "chartOptions": {
        "aggregationType": "sum",
        "binsNumber": 10,
        "categoryFieldKeys": [],
        "chartType": "bar",
        "isStacked": false,
        "seriesFieldKeys": [],
        "wordFrequency": "-1"
       },
       "tableOptions": {},
       "type": "details",
       "viewOptionsGroup": [
        {
         "tabItems": [
          {
           "key": "0",
           "name": "Table",
           "options": {},
           "type": "table"
          }
         ]
        }
       ]
      }
     },
     "sync_state": {
      "isSummary": false,
      "is_jupyter": false,
      "language": "scala",
      "table": {
       "rows": [
        {
         "0": "/synfs/notebook/07d80e2d-a99f-4210-9687-6821d94cc581/mnt/lakehouse/Baraa_LH/Files",
         "1": "/mnt/lakehouse/Baraa_LH/Files",
         "2": "job",
         "3": "abfss://63bd4ac8-18b7-4ec1-8ee9-681feee6113e@onelake.dfs.fabric.microsoft.com/84285eaa-9ab8-4dc9-8ecc-005a40bcda83/Files",
         "4": "Lakehouse",
         "index": 0,
         "key": 0
        }
       ],
       "schema": [
        {
         "key": "0",
         "name": "localPath",
         "type": "string"
        },
        {
         "key": "1",
         "name": "mountPoint",
         "type": "string"
        },
        {
         "key": "2",
         "name": "scope",
         "type": "string"
        },
        {
         "key": "3",
         "name": "source",
         "type": "string"
        },
        {
         "key": "4",
         "name": "storageType",
         "type": "string"
        }
       ],
       "truncated": false
      }
     },
     "type": "Synapse.DataFrame"
    }
   },
   "version": "0.1"
  },
  "widgets": {
   "application/vnd.jupyter.widget-state+json": {
    "state": {
     "16f6f92ca1b240819f55f4e768137add": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "17a309fe3767470986dc87a35512e3e5": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "4f409e31a64e43a1a5d0d162f6114b24": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "5ef42f92d8494260a7515c0ff459c73f": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "6a40db3a6417464b878af7d9281f1fc9": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "ProgressStyleModel",
      "state": {
       "description_width": ""
      }
     },
     "96c05bf449794b72a335f7704a186cba": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "FloatProgressModel",
      "state": {
       "bar_style": "success",
       "layout": "IPY_MODEL_bd13547135f74ac5bbc4d68d2f4b360c",
       "style": "IPY_MODEL_6a40db3a6417464b878af7d9281f1fc9",
       "value": 100
      }
     },
     "aafe135e4f374a259e5dd1b2bdb06632": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_5ef42f92d8494260a7515c0ff459c73f",
       "style": "IPY_MODEL_e8f6dc7cc0004f8487c20afe40972a83",
       "value": "Operation https://api.fabric.microsoft.com/v1/workspaces/63bd4ac8-18b7-4ec1-8ee9-681feee6113e/warehouses successfully completed: 100%"
      }
     },
     "bd13547135f74ac5bbc4d68d2f4b360c": {
      "model_module": "@jupyter-widgets/base",
      "model_module_version": "2.0.0",
      "model_name": "LayoutModel",
      "state": {}
     },
     "bd262fc1dd8045a69e3fc89767d2145d": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLModel",
      "state": {
       "layout": "IPY_MODEL_16f6f92ca1b240819f55f4e768137add",
       "style": "IPY_MODEL_17a309fe3767470986dc87a35512e3e5",
       "value": " 100/100 [00:20&lt;00:00,  4.99it/s]"
      }
     },
     "e8f6dc7cc0004f8487c20afe40972a83": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HTMLStyleModel",
      "state": {
       "description_width": "",
       "font_size": null,
       "text_color": null
      }
     },
     "f3502c6ccbcf4cb5b9c4aed77be8ed51": {
      "model_module": "@jupyter-widgets/controls",
      "model_module_version": "2.0.0",
      "model_name": "HBoxModel",
      "state": {
       "children": [
        "IPY_MODEL_aafe135e4f374a259e5dd1b2bdb06632",
        "IPY_MODEL_96c05bf449794b72a335f7704a186cba",
        "IPY_MODEL_bd262fc1dd8045a69e3fc89767d2145d"
       ],
       "layout": "IPY_MODEL_4f409e31a64e43a1a5d0d162f6114b24"
      }
     }
    },
    "version_major": 2,
    "version_minor": 0
   }
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
